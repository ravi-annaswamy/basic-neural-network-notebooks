{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplest neural network \n",
    "Single layer, (no hidden layers) using backprop\n",
    "\n",
    "Original code from Andrew Trask\n",
    "\n",
    "http://iamtrask.github.io/2015/07/12/basic-python-network/\n",
    "\n",
    "Notebook version: Ravi Annaswamy March 30, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X Matrix holds input test cases\n",
    "\n",
    "\n",
    "Neural networks learn mappings from an input situation to an output action/response/judgement.\n",
    "\n",
    "The mapping we want it to learn here is the following:\n",
    "\n",
    "0,0,1 ->0\n",
    "\n",
    "0,1,1 ->0\n",
    "\n",
    "1,0,1 ->1\n",
    "\n",
    "1,1,1 ->1\n",
    "\n",
    "Basically column 3 has no effect on the output, and if you look closely column 2 also has no effect. Only column one directly drives output. Can our network learn this?\n",
    "\n",
    "Let us create an input dataset with four rows (four cases) and three columns each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y matrix holds output test cases\n",
    "\n",
    "Corresponding outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([[0,0,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Weights Matrix will hold the knowledge\n",
    "\n",
    "We will create a single layer network 3 input cells and one output cell, means that we\n",
    "need a 3x1 weight matrix.\n",
    "\n",
    "We call this as a single layer network, because there is one layer of weights to be learnt. We will call input layer as L0 and the output layer as L1.\n",
    "\n",
    "We will use numpy random generator and ask for 3 rows of 1 weight each.\n",
    "We will have these centered at 0 by initially generating from 0 to 2 and subtracting 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W0 = 2*np.random.random((3,1))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16595599],\n",
       "       [ 0.44064899],\n",
       "       [-0.99977125]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating output for a test case\n",
    "\n",
    "Let us present the inputs to an input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L0 = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is obtained by multiplying the inputs one row at a time with the matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, the first input case [0,0,1] is processed by these weights like this:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.99977125])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X[0],W0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing\n",
    "\n",
    "We could do all input rows at the same time! We save the output as Layer 1, L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99977125],\n",
       "       [-0.55912226],\n",
       "       [-1.16572724],\n",
       "       [-0.72507825]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1 = np.dot(L0,W0); L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is cool because we can find our error against the four expected outputs stored in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99977125],\n",
       "       [ 0.55912226],\n",
       "       [ 2.16572724],\n",
       "       [ 1.72507825]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1_error= y-L1; L1_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For case 1, we expected the network to give out a 0, but since the fourth input was on and it passed along\n",
    "its value, the output was -0.999, so we need to reduce the output to 0, and so the amount to change is 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99954255],\n",
       "       [-0.31261771],\n",
       "       [-2.52464724],\n",
       "       [-1.25081673]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1_delta = L1_error * L1; L1_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the direction in which we have to adjust the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W0 += np.dot(L0.T, L1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.94141996],\n",
       "       [-1.12278545],\n",
       "       [-6.08739548]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has this improved outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L1 = np.dot(L0, W0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -6.08739548],\n",
       "       [ -7.21018093],\n",
       "       [-10.02881544],\n",
       "       [-11.15160089]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, we expected first two rows to move towards 0 and the other two to move towards 1, but that is not what we see.\n",
    "\n",
    "Somehow we have not scaled the error into a proper feedback that will update weights just enough.\n",
    "\n",
    "Maybe we need to run a few more rounds?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([[-0.99977125],\n",
      "       [-0.55912226],\n",
      "       [-1.16572724],\n",
      "       [-0.72507825]]))\n",
      "(1, array([[ -6.08739548],\n",
      "       [ -7.21018093],\n",
      "       [-10.02881544],\n",
      "       [-11.15160089]]))\n",
      "(2, array([[-341.24624596],\n",
      "       [-529.86554361],\n",
      "       [-591.30342369],\n",
      "       [-779.92272134]]))\n",
      "(3, array([[-1356838.15721241],\n",
      "       [-2246843.64480525],\n",
      "       [-2316378.63067319],\n",
      "       [-3206384.11826603]]))\n",
      "(4, array([[ -2.25358321e+13],\n",
      "       [ -3.78650417e+13],\n",
      "       [ -3.81823477e+13],\n",
      "       [ -5.35115572e+13]]))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "W0 = 2*np.random.random((3,1))-1\n",
    "for iter in xrange(5):\n",
    "        L0 = X\n",
    "        L1 = np.dot(L0, W0)\n",
    "        L1_error = y - L1\n",
    "        L1_delta = L1_error * L1\n",
    "        W0 +=  np.dot(L0.T, L1_delta)\n",
    "        print(iter, L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ouch! What happened here?\n",
    "\n",
    "We see the outputs crazily shooting to large numbers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter the Sigmoid.\n",
    "\n",
    "\n",
    "Very clever people, who had experience developing feedback control systems, got the insight into what is happening.\n",
    "\n",
    "If you feed unscaled feedback, it becomes positive feedback and values begin to shoot out!\n",
    "\n",
    "One solution is to use a multiplier like 0.01 to limit how much the weights will change each iteration. \n",
    "\n",
    "For this example, it will work, but in other cases, it will just postpone the out of control dance. What we really need is a way to ensure that the feedback signal will always be far less than one.\n",
    "\n",
    "This is done by rescaling outputs themselves in the range [0-1].\n",
    "\n",
    "The Sigmoid is a beautiful function that transforms a value ranging \n",
    "from negative infinity to positive infinity to range of [0-1].\n",
    "\n",
    "Remember, we need to limit both the output and the feedback amount using this function.\n",
    "\n",
    "First the function itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-20, 2.0611536181902037e-09)\n",
      "(100, 1.0)\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "print(-20, sigmoid(-20))\n",
    "print(100, sigmoid(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us make the feedback proportional to the slope of the output.\n",
    "In other words, if the output is large and negative, the feedback should be \n",
    "large and negative and so on.\n",
    "\n",
    "Andy gives the beautiful intuition that the gradient shows how sure you are.\n",
    "\n",
    "If x is 1, gradient will be 1 * (1-1) = 0\n",
    "if x is 0, gradient will be 0 * (1-0) = 0\n",
    "but if x is 0.5, gradient will be 0.5 * 0.5 = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "(1, 0)\n",
      "(0.5, 0.25)\n"
     ]
    }
   ],
   "source": [
    "def gradient(x):\n",
    "    return x*(1-x)\n",
    "print(0, gradient(0))\n",
    "print(1, gradient(1))\n",
    "print(0.5, gradient(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us redo the forward computation and error delta with this new scheme.\n",
    "\n",
    "Since we have updated W0 once or twice above, I am resetting to initial known seed state in the first two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('L1: ', array([[ 0.2689864 ],\n",
      "       [ 0.36375058],\n",
      "       [ 0.23762817],\n",
      "       [ 0.3262757 ]]))\n",
      "('Error: ', array([[-0.2689864 ],\n",
      "       [-0.36375058],\n",
      "       [ 0.76237183],\n",
      "       [ 0.6737243 ]]))\n",
      "('L1 gradient:', array([[ 0.19663272],\n",
      "       [ 0.23143609],\n",
      "       [ 0.18116102],\n",
      "       [ 0.21981987]]))\n",
      "('L1_delta: ', array([[-0.05289153],\n",
      "       [-0.08418501],\n",
      "       [ 0.13811206],\n",
      "       [ 0.14809799]]))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "W0 = 2*np.random.random((3,1))-1\n",
    "\n",
    "L0 = X\n",
    "L1 = sigmoid(np.dot(L0, W0))\n",
    "print('L1: ',L1)\n",
    "\n",
    "L1_error = y - L1\n",
    "print('Error: ', L1_error)\n",
    "\n",
    "L1_gradient = gradient(L1)\n",
    "print('L1 gradient:', L1_gradient)\n",
    "\n",
    "L1_delta = L1_error * L1_gradient\n",
    "print('L1_delta: ', L1_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to update weights, but by how much? We use the delta rule, that says weight update should depend on how high an input was and how much the error was! Makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28621005],\n",
       "       [ 0.06391297],\n",
       "       [ 0.14913351]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(L0.T, L1_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12025406],\n",
       "       [ 0.50456196],\n",
       "       [-0.85063774]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W0 += np.dot(L0.T, L1_delta)\n",
    "W0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see if this will improve output next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29929909],\n",
       "       [ 0.41433436],\n",
       "       [ 0.32511054],\n",
       "       [ 0.44378327]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1 = sigmoid(np.dot(L0, W0))\n",
    "L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zeroth iteration, the output was:\n",
    "\n",
    "    array([[-0.99977125],\n",
    "       [-0.55912226],\n",
    "       [-1.16572724],\n",
    "       [-0.72507825]])\n",
    "    \n",
    "    Now it is:\n",
    "        array([[ 0.29929909],\n",
    "       [ 0.41433436],\n",
    "       [ 0.32511054],\n",
    "       [ 0.44378327]])\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like the outputs are moving in the right direction, though\n",
    "        they seem to have overshot beyond 0..\n",
    "        \n",
    "Let us try more iterations, now that we have found a way to \n",
    "tame the feedback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, array([[ 0.00966449],\n",
      "       [ 0.00786506],\n",
      "       [ 0.99358898],\n",
      "       [ 0.99211957]]))\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "W0 = 2*np.random.random((3,1))-1\n",
    "for iter in xrange(10000):\n",
    "        L0 = X\n",
    "        L1 = sigmoid(np.dot(L0, W0))\n",
    "        L1_error = y - L1\n",
    "        L1_delta = L1_error * gradient(L1)\n",
    "        W0 += np.dot(L0.T, L1_delta)\n",
    "print(iter, L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Entire program\n",
    "So here is the entire program for clarity..\n",
    "\n",
    "Please note that I have made two final changes.\n",
    "One, I have moved the seed reset command to reset the random seed just before we sample the initial weights. \n",
    "\n",
    "Second, I am  now printing results once every 1000 iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([[ 0.2689864 ],\n",
      "       [ 0.36375058],\n",
      "       [ 0.23762817],\n",
      "       [ 0.3262757 ]]))\n",
      "(1000, array([[ 0.03176745],\n",
      "       [ 0.02575143],\n",
      "       [ 0.97907779],\n",
      "       [ 0.97416005]]))\n",
      "(2000, array([[ 0.02210122],\n",
      "       [ 0.01793507],\n",
      "       [ 0.985409  ],\n",
      "       [ 0.98200541]]))\n",
      "(3000, array([[ 0.0179128 ],\n",
      "       [ 0.01454746],\n",
      "       [ 0.98815758],\n",
      "       [ 0.98540875]]))\n",
      "(4000, array([[ 0.01544409],\n",
      "       [ 0.0125494 ],\n",
      "       [ 0.98978021],\n",
      "       [ 0.98741602]]))\n",
      "(5000, array([[ 0.01377152],\n",
      "       [ 0.01119485],\n",
      "       [ 0.99088089],\n",
      "       [ 0.98877656]]))\n",
      "(6000, array([[ 0.01254323],\n",
      "       [ 0.01019961],\n",
      "       [ 0.99168995],\n",
      "       [ 0.98977602]]))\n",
      "(7000, array([[ 0.01159234],\n",
      "       [ 0.0094288 ],\n",
      "       [ 0.99231678],\n",
      "       [ 0.99054995]]))\n",
      "(8000, array([[ 0.01082824],\n",
      "       [ 0.00880917],\n",
      "       [ 0.99282079],\n",
      "       [ 0.99117199]]))\n",
      "(9000, array([[ 0.01019693],\n",
      "       [ 0.00829707],\n",
      "       [ 0.99323743],\n",
      "       [ 0.991686  ]]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "np.random.seed(1)\n",
    "W0 = 2*np.random.random((3,1))-1\n",
    "for iter in xrange(10000):\n",
    "        L0 = X\n",
    "        L1 = sigmoid(np.dot(L0, W0))\n",
    "        L1_error = y - L1\n",
    "        L1_delta = L1_error * gradient(L1)\n",
    "        W0 += np.dot(L0.T, L1_delta)\n",
    "        if iter%1000==0:\n",
    "            print(iter, L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move off, is this network all powerful?\n",
    "\n",
    "Let us try this mapping:\n",
    "    \n",
    "    0,0,1 -> 0\n",
    "    0,1,1 -> 1\n",
    "    1,0,1 -> 1\n",
    "    1,1,1 -> 1\n",
    "    \n",
    "    which is an OR mapping on columns one and two, and third column is just noise with no information to predict output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([[ 0.2689864 ],\n",
      "       [ 0.36375058],\n",
      "       [ 0.23762817],\n",
      "       [ 0.3262757 ]]))\n",
      "(1000, array([[ 0.05479081],\n",
      "       [ 0.96577999],\n",
      "       [ 0.96577641],\n",
      "       [ 0.99992722]]))\n",
      "(2000, array([[ 0.03773302],\n",
      "       [ 0.97633606],\n",
      "       [ 0.97633549],\n",
      "       [ 0.99997696]]))\n",
      "(3000, array([[ 0.03044286],\n",
      "       [ 0.98087556],\n",
      "       [ 0.98087536],\n",
      "       [ 0.99998806]]))\n",
      "(4000, array([[ 0.02617603],\n",
      "       [ 0.98353992],\n",
      "       [ 0.98353983],\n",
      "       [ 0.99999247]]))\n",
      "(5000, array([[ 0.0232981 ],\n",
      "       [ 0.98534006],\n",
      "       [ 0.98534001],\n",
      "       [ 0.99999472]]))\n",
      "(6000, array([[ 0.02119131],\n",
      "       [ 0.98665939],\n",
      "       [ 0.98665936],\n",
      "       [ 0.99999604]]))\n",
      "(7000, array([[ 0.01956422],\n",
      "       [ 0.9876792 ],\n",
      "       [ 0.98767918],\n",
      "       [ 0.99999689]]))\n",
      "(8000, array([[ 0.01825921],\n",
      "       [ 0.98849769],\n",
      "       [ 0.98849768],\n",
      "       [ 0.99999748]]))\n",
      "(9000, array([[ 0.01718266],\n",
      "       [ 0.98917326],\n",
      "       [ 0.98917325],\n",
      "       [ 0.99999791]]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "y = np.array([[0,1,1,1]]).T\n",
    "\n",
    "np.random.seed(1)\n",
    "W0 = 2*np.random.random((3,1))-1\n",
    "for iter in xrange(10000):\n",
    "        L0 = X\n",
    "        L1 = sigmoid(np.dot(L0, W0))\n",
    "        L1_error = y - L1\n",
    "        L1_delta = L1_error * gradient(L1)\n",
    "        W0 += np.dot(L0.T, L1_delta)\n",
    "        if iter%1000==0:\n",
    "            print(iter, L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! It did. Let us try the and mapping\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([[ 0.2689864 ],\n",
      "       [ 0.36375058],\n",
      "       [ 0.23762817],\n",
      "       [ 0.3262757 ]]))\n",
      "(1000, array([[  2.43631161e-04],\n",
      "       [  5.54627689e-02],\n",
      "       [  5.54627683e-02],\n",
      "       [  9.33989117e-01]]))\n",
      "(2000, array([[  7.45477397e-05],\n",
      "       [  3.81302776e-02],\n",
      "       [  3.81302776e-02],\n",
      "       [  9.54707154e-01]]))\n",
      "(3000, array([[  3.80129661e-05],\n",
      "       [  3.07209321e-02],\n",
      "       [  3.07209321e-02],\n",
      "       [  9.63537553e-01]]))\n",
      "(4000, array([[  2.37428297e-05],\n",
      "       [  2.63893749e-02],\n",
      "       [  2.63893749e-02],\n",
      "       [  9.68693007e-01]]))\n",
      "(5000, array([[  1.65408129e-05],\n",
      "       [  2.34709841e-02],\n",
      "       [  2.34709841e-02],\n",
      "       [  9.72163723e-01]]))\n",
      "(6000, array([[  1.23371120e-05],\n",
      "       [  2.13365563e-02],\n",
      "       [  2.13365563e-02],\n",
      "       [  9.74700716e-01]]))\n",
      "(7000, array([[  9.64126894e-06],\n",
      "       [  1.96894054e-02],\n",
      "       [  1.96894054e-02],\n",
      "       [  9.76657736e-01]]))\n",
      "(8000, array([[  7.79438364e-06],\n",
      "       [  1.83691746e-02],\n",
      "       [  1.83691746e-02],\n",
      "       [  9.78225841e-01]]))\n",
      "(9000, array([[  6.46565619e-06],\n",
      "       [  1.72806916e-02],\n",
      "       [  1.72806916e-02],\n",
      "       [  9.79518360e-01]]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "y = np.array([[0,0,0,1]]).T\n",
    "\n",
    "np.random.seed(1)\n",
    "W0 = 2*np.random.random((3,1))-1\n",
    "for iter in xrange(10000):\n",
    "        L0 = X\n",
    "        L1 = sigmoid(np.dot(L0, W0))\n",
    "        L1_error = y - L1\n",
    "        L1_delta = L1_error * gradient(L1)\n",
    "        W0 += np.dot(L0.T, L1_delta)\n",
    "        if iter%1000==0:\n",
    "            print(iter, L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yes, it does.\n",
    "\n",
    "How about the XOR mapping which detects the condition where\n",
    "the output turns on only when ONE of the two inputs is on, but not whe\n",
    "both are on!\n",
    "\n",
    "That is, we want:\n",
    "    \n",
    "0,0,1->0 \n",
    "\n",
    "0,1,1->1 \n",
    "\n",
    "1,0,1->1 \n",
    "\n",
    "1,1,1->0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([[ 0.2689864 ],\n",
      "       [ 0.36375058],\n",
      "       [ 0.23762817],\n",
      "       [ 0.3262757 ]]))\n",
      "(1000, array([[ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5]]))\n",
      "(2000, array([[ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5]]))\n",
      "(3000, array([[ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5]]))\n",
      "(4000, array([[ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5]]))\n",
      "(5000, array([[ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5]]))\n",
      "(6000, array([[ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5]]))\n",
      "(7000, array([[ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5]]))\n",
      "(8000, array([[ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5]]))\n",
      "(9000, array([[ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5],\n",
      "       [ 0.5]]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0,1],[0,1,1],[1,0,1],[1,1,1]])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "\n",
    "np.random.seed(1)\n",
    "W0 = 2*np.random.random((3,1))-1\n",
    "for iter in xrange(10000):\n",
    "        L0 = X\n",
    "        L1 = sigmoid(np.dot(L0, W0))\n",
    "        L1_error = y - L1\n",
    "        L1_delta = L1_error * gradient(L1)\n",
    "        W0 += np.dot(L0.T, L1_delta)\n",
    "        if iter%1000==0:\n",
    "            print(iter, L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHAT!\n",
    "\n",
    "No it did not.\n",
    "\n",
    "Turns out it CANNOT. A network without an intermediate 'thinking' layer\n",
    "layer cannot learn this mapping. \n",
    "\n",
    "Why? You have to first process the inputs to see there is an OR condition, \n",
    "and separately to see if there is an AND condition. This should happen in layer 1 and \n",
    "another layer should look at this to determine the possibilities.\n",
    "\n",
    "That is subject for the next notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
